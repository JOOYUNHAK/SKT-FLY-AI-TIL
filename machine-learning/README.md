# Machine Learning
## Machine Learning이란
많은 양의 데이터를 제공하여 명시적으로 프로그래밍하지 않고 신경망과 딥 러닝을 사용하여 시스템이 자율적으로 학습하고 개선할 수 있게 해주는 것
## 정형 데이터의 구조
+ 일반적으로 RDBMS의 튜플을 관측치 또는 샘플이라 하며, 속성을 변수, 마지막 원하는 값을 타겟이라 함

## 머신러닝 알고리즘 
+ `회귀`: 예측하고자 하는 타겟값이 숫자인 경우이며, 예측 결과가 연속성을 띔( 가격, 거래량 예측 )
+ `분류`: 예측하고자 하는 타겟값이 범주형 변수일 경우이며, 연속성을 띄지 않음
    - **이진분류:** 둘 중에 하나의 결과값으로 분류하는 것( 합격, 불합격 )
    - **다중분류**: 여러 결과 값중 하나로 분류하는 것( 학점 A, B, C, D )

## 좋은 학습이란
새로운 데이터가 들어왔을 때에도 잘 예측하는것( `일반화` )

## 과소적합과 과대적합
+ `과소적합`: 모델은 복잡한데 데이터의 양이 부족해 학습이 안되는 경우
+ `과대적합`: 데이터의 양은 충분한데 모델은 엉성한 경우( `일반화`가 안된 상태 )

## 과대적합을 피하는 방법
+ `데이터 나누기`: 학습 데이터와 테스트 데이터를 나눠서 수행( 데이터의 80%는 학습, 나머지 20%는 테스트에 이용, 학습 데이터 중 20%정도는 검증 데이터로 이용할 수 있음. 하지만 검증 데이터에 결과가 잘 나오게끔 학습시키므로 검증 데이터쪽에 최적화가 될 수 있음 )
+ `교차 검증`: 매 단계마다 검증 데이터를 변경하면서 학습을 시켜 고정된 검증 데이터에 최적화 되는 것을 방지함
+ `라벨 인코딩`: 문자로 표현된 범주형 데이터들을 숫자로 변경하는 것 ( 이진 분류인 경우 양성에 1을 주는게 좋음 )
+ `원-핫 인코딩`: 순위가 없는 경우 단순 분류를 위해 숫자로 변경하는 경우 숫자가 높을 수록 중요도가 높다는 오류의 위험성을 막기 위해 열을 더 만들어 해당 부분에만 1로 표현
    > A형 0, B형 1, O형 2, AB형 3 이런식이 아니라, A, B, O, AB형 별로 컬럼을 만들고 해당하는 혈액형만 1 나머지는 0
+ `특성 스케일링`: 입력 특성들의 스케일이 다를 경우 특정 특성때문에 결과 값이 크게 바뀌어 잘 동작하지 않을 경우를 대비해 특성들을 스케일링 하는 것( 나이와 연봉이 있는 경우 연봉의 변화에 따라 결과가 크게 바뀜 )
    - `Min-Max 스케일링`( 최대 최소 정규화 ): 모든 특성이 0과 1사이의 수로 변경하는 것
    - `표준화`: 모든 특성(컬럼)의 평균을 0, 분산이 1이 되도록 변환
        - 이상치에 영향을 덜 받는다 -> Min-Max 스케일링은 max의 값에 따라 max가 너무 클 경우 영향을 받는데 표준화는 그럴 걱정 없음

## 데이터 정제    
+ `이상치`: 쓰레기 값들을 없애는 것
+ `결측치`: 결측치가 많은 특성을 삭제하고 특별한 값으로 채움( 0, 평균, 최소, 최대.. )

## 평가방법
분류 알고리즘의 평가는 **정확도**가 가장 중요하지만, 사용하려는 인공지능의 모델에 따라(**민감도**와 **정밀도** 중 어떤게 더 좋아야 하는지 생각해야됨)
> **정밀도**는 예측을 Positive로 한 대상중 예측값과 실제값이 Positive로 일치한 데이터의 비율 <br> 
  **재현율(민감도)** 은 실제값이 Positive인 대상중 예측값과 실제값이 Positive로 일치한 데이터의 비율 <br>
  재현율이 상대적으로 더 중요한 경우는 실제값이 Positive인 데이터를 Negative로 잘못 판단하게 되면 큰 영향이 발생하는 경우 ( 암 진단 ) <br>
  정밀도가 상대적으로 더 중요한 경우는 실제 Negative인 데이터를 Positive로 잘못 판단하면 큰 영향이 발생하는 경우( 스팸 메일 분류 )
+ **분류 모델**
    - `혼동 행렬`
        - TP: Positive로 예측 했는데 맞았을 경우 
        - FP: Positive로 예측 했는데 틀렸을 경우
        - TN: Negative로 예측 했는데 맞았을 경우
        - FN: Negative로 예측 했는데 틀렸을 경우
    - `F1 점수`: 정밀도와 재현율을 하나의 숫자로 표현하는데 1에 가까울 수록 좋음
    - `Threshold`: 애매한 값을 이분법으로 확실히 분류할 기준이 필요한데 이 기준을 임계값이라고 함.
    - `ROC`: FPR이 변할 때 TPR이 어떻게 변하는지를 나타내는 곡선
        - FPR: 음성인 케이스에 대해 양성으로 잘못 예측한 비율
        - TPR: 양성인 케이스에 대해 양성으로 잘 예측한 비율
    - `AUROC`: ROC의 밑 면적 넓이로 ROC는 1에 가까울 수록 좋으므로 AUROC의 값이 클수록 좋음
+ **회귀 모델**
    - `오차`: 실젯값과 예측값의 차이( 두 수를 절댓값을 해서 더함 0에 가까울수록 좋음 )
        - MSE: 오차의 제곱의 평균
        - RMSE: MSE 값에 루트를 적용한 값
    - `결정계수`: 1 - ( 회귀 이후 오차 / 회귀 이전 오차 ) 값으로 회귀 이후 에러가 0에 가까울 수록 회귀가 잘 된 상태이기 때문에 결정계수가 1에 가까울 수록 좋음

